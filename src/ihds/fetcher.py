#!/usr/bin/env python3
"""
IHDS Daily View Fetcher
æ¯å¤©è‡ªåŠ¨ä¸‹è½½ Human Design æ¯æ—¥è§†å›¾ï¼Œå¹¶ç”Ÿæˆä¸­è‹±æ–‡åŒè¯­ Markdown æ–‡ä»¶
"""

import os
import re
import json
import base64
import html
import requests
from datetime import datetime
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Optional, Dict, Any


class IHDSDailyViewFetcher:
    """IHDS Daily View å†…å®¹æŠ“å–å™¨"""
    
    DAILY_VIEW_URL = "https://ihdschool.com/the-daily-view"
    DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"
    
    def __init__(self, deepseek_api_key: str, output_dir: str = None):
        self.api_key = deepseek_api_key
        # é»˜è®¤è¾“å‡ºåˆ°é¡¹ç›®æ ¹ç›®å½•çš„ output/daily_views
        if output_dir:
            self.base_output_dir = Path(output_dir)
        else:
            # ä» src/ihds/fetcher.py å‘ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent.parent
            self.base_output_dir = project_root / "output" / "daily_views"
        self.base_output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ—¥æœŸå­—ç¬¦ä¸²ï¼Œç›®å½•ä¼šåœ¨è§£æå†…å®¹ååˆ›å»º
        self.date_str = datetime.now().strftime("%Y-%m-%d")
        self.output_dir = None
        self.images_dir = None
    
    def _extract_gate_line_numbers(self, content: Dict[str, Any]) -> tuple:
        """ä»å†…å®¹ä¸­æå– Gate å·å’Œ Line å·"""
        gate_num = ""
        line_num = ""
        
        # ä» gate_title æå– Gate å· (ä¾‹å¦‚: "Gate 54 - The Marrying Maiden" -> "54")
        gate_title = content.get('gate_title', '')
        gate_match = re.search(r'Gate\s+(\d+)', gate_title)
        if gate_match:
            gate_num = gate_match.group(1)
        
        # ä» line_title æå– Line å· (ä¾‹å¦‚: "Line 1 - Influence" -> "1")
        line_title = content.get('line_title', '')
        line_match = re.search(r'Line\s+(\d+)', line_title)
        if line_match:
            line_num = line_match.group(1)
        
        return gate_num, line_num
    
    def _setup_daily_directory(self, content: Dict[str, Any]):
        """æ ¹æ®å†…å®¹åˆ›å»ºä»Šå¤©çš„ç›®å½•ï¼Œæ ¼å¼: 2026-01-06-54.1"""
        gate_num, line_num = self._extract_gate_line_numbers(content)
        
        # æ„å»ºç›®å½•å: æ—¥æœŸ-Gateå·.Lineå·
        if gate_num and line_num:
            dir_name = f"{self.date_str}-{gate_num}.{line_num}"
        elif gate_num:
            dir_name = f"{self.date_str}-{gate_num}"
        else:
            dir_name = self.date_str
        
        self.output_dir = self.base_output_dir / dir_name
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.images_dir = self.output_dir / "images"
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        return dir_name
        
    def fetch_page(self) -> str:
        """è·å–ç½‘é¡µ HTML å†…å®¹"""
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }
        response = requests.get(self.DAILY_VIEW_URL, headers=headers, timeout=30)
        response.raise_for_status()
        return response.text
    
    def download_image(self, url: str, filename: str) -> str:
        """ä¸‹è½½å›¾ç‰‡å¹¶è¿”å›æœ¬åœ°è·¯å¾„"""
        local_path = self.images_dir / filename
        
        # å¦‚æœå›¾ç‰‡å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if local_path.exists():
            return str(local_path.relative_to(self.output_dir))
        
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            with open(local_path, 'wb') as f:
                f.write(response.content)
            return str(local_path.relative_to(self.output_dir))
        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url}: {e}")
            return url  # è¿”å›åŸå§‹ URL
    
    def download_images(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸‹è½½æ‰€æœ‰å›¾ç‰‡å¹¶æ›´æ–°å†…å®¹ä¸­çš„è·¯å¾„"""
        # ä¸‹è½½ Gate å›¾ç‰‡
        if content.get('gate_image_url') and content.get('gate_image_filename'):
            content['gate_image_local'] = self.download_image(
                content['gate_image_url'], 
                content['gate_image_filename']
            )
        
        # å¤„ç† Rave Mandala base64 å›¾ç‰‡
        if content.get('rave_mandala_b64'):
            try:
                b64_data = content['rave_mandala_b64']
                
                # è§£ç  HTML å®ä½“ï¼ˆå¦‚ &amp; â†’ &ï¼‰
                b64_data = html.unescape(b64_data)
                
                # æ¸…ç†ç©ºç™½å­—ç¬¦
                b64_data = b64_data.strip().replace('\n', '').replace('\r', '').replace(' ', '')
                
                # ä¿®å¤å¯èƒ½çš„ padding é—®é¢˜
                missing_padding = len(b64_data) % 4
                if missing_padding:
                    b64_data += '=' * (4 - missing_padding)
                
                img_data = base64.b64decode(b64_data)
                rave_mandala_path = self.images_dir / 'rave_mandala.png'
                with open(rave_mandala_path, 'wb') as f:
                    f.write(img_data)
                content['rave_mandala_local'] = str(rave_mandala_path.relative_to(self.output_dir))
                print(f"   âœ… Rave Mandala åœ–ç‰‡å·²ä¿å­˜ ({len(img_data)} å­—ç¯€)")
            except Exception as e:
                print(f"   âš ï¸ Rave Mandala è§£ç¢¼å¤±æ•—: {e}")
        
        return content
    
    def parse_content(self, page_html: str) -> Dict[str, Any]:
        """è§£æç½‘é¡µå†…å®¹ï¼Œæå–æ¯æ—¥è§†å›¾ä¿¡æ¯ï¼ˆä¸ä¸‹è½½å›¾ç‰‡ï¼‰"""
        soup = BeautifulSoup(page_html, 'html.parser')
        content = {}
        
        # æå– Gate å›¾ç‰‡ URLï¼ˆç¨åä¸‹è½½ï¼‰
        gate_img = soup.find('img', class_='gate')
        if gate_img and gate_img.get('src'):
            img_url = gate_img['src']
            img_filename = img_url.split('/')[-1]
            content['gate_image_url'] = img_url
            content['gate_image_filename'] = img_filename
        
        # ä¿å­˜ base64 æ•°æ®ç”¨äºç¨åå¤„ç†
        b64_match = re.search(r'data:image/png;base64,([^"]+)', page_html)
        if b64_match:
            content['rave_mandala_b64'] = b64_match.group(1)
        
        # æå– Gate æ ‡é¢˜ (ä¾‹å¦‚: "Gate 58 - The Joyous")
        gate_title_tag = soup.find('h2')
        if gate_title_tag:
            content['gate_title'] = gate_title_tag.get_text(strip=True)
        
        # æå– Gate å‰¯æ ‡é¢˜ (ä¾‹å¦‚: "Gate of Vitality - The Vitality to Challenge")
        gate_subtitle_tag = soup.find('h4', string=lambda x: x and 'Gate of' in x) or soup.find('h4')
        if gate_subtitle_tag:
            em_tag = gate_subtitle_tag.find('em')
            if em_tag:
                content['gate_subtitle'] = em_tag.get_text(strip=True)
            else:
                content['gate_subtitle'] = gate_subtitle_tag.get_text(strip=True)
        
        # æå– Lead æè¿° (ä¸»è¦æè¿°æ–‡å­—)
        lead_p = soup.find('p', class_='lead')
        if lead_p:
            content['lead_description'] = lead_p.get_text(strip=True)
        
        # æå– Gate èŒƒå›´ (ä¾‹å¦‚: "Gate 10 < Gate 58 > Gate 38")
        gate_range_p = soup.find('p', class_='text-lg')
        if gate_range_p:
            content['gate_range'] = gate_range_p.get_text(strip=True)
        
        # æå– Cross ä¿¡æ¯ (ä¾‹å¦‚: "Right Angle Cross of Service 4 | Godhead - Vishnu")
        cross_h4 = soup.find('h4', string=lambda x: x and 'Cross' in x if x else False)
        if cross_h4:
            content['cross_info'] = cross_h4.get_text(strip=True)
        
        # æå– Quarter å’Œ Theme ä¿¡æ¯
        quarter_p_list = soup.find_all('p', class_='text-lg')
        for p in quarter_p_list:
            text = p.get_text(strip=True)
            if 'Quarter' in text:
                content['quarter_theme'] = text
                break
        
        # æå– Channel æè¿° (ä¸»è¦å†…å®¹æ®µè½)
        # å¯»æ‰¾åŒ…å« "This Gate is part of" çš„æ®µè½
        all_paragraphs = soup.find_all('p')
        main_paragraphs = []
        found_main = False
        for p in all_paragraphs:
            text = p.get_text(strip=True)
            if text and 'This Gate is part of' in text:
                main_paragraphs.append(text)
                found_main = True
            elif found_main and len(text) > 100:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ— å…³å†…å®¹
                if any(skip in text for skip in [
                    'Daily View reflects', 'Exaltation', 'Detriment',
                    'Copyright', 'Projectors are designed', 'Unlike energy Types',
                    'young people', 'register for an IHDS'
                ]):
                    break  # åœæ­¢æ”¶é›†
                main_paragraphs.append(text)
        if main_paragraphs:
            content['main_description'] = '\n\n'.join(main_paragraphs)
        
        # æå– Line ä¿¡æ¯ (ä¾‹å¦‚: "Line 3 - Electricity")
        line_h6 = soup.find('h6', string=lambda x: x and 'Line' in x if x else False)
        if line_h6:
            content['line_title'] = line_h6.get_text(strip=True)
        
        # æå– Exaltation å’Œ Detriment
        col_md_6_divs = soup.find_all('div', class_='col-md-6')
        for div in col_md_6_divs:
            paragraphs = div.find_all('p')
            for p in paragraphs:
                text = p.get_text(strip=True)
                if 'Exaltation' in text:
                    # æå– Exaltation å†…å®¹
                    content['exaltation'] = text.replace('Exaltation:', '').strip()
                elif 'Detriment' in text:
                    # æå– Detriment å†…å®¹
                    content['detriment'] = text.replace('Detriment:', '').strip()
        
        # æå–é¡µè„šè¯´æ˜
        footer_text = soup.find('p', string=lambda x: x and 'The Daily View reflects' in x if x else False)
        if footer_text:
            content['footer_note'] = footer_text.get_text(strip=True)
        else:
            content['footer_note'] = (
                "The Daily View reflects the impact the Sun (70% of the neutrino influence) "
                "is having on humanity as it moves through the Gates and Lines of the Mandala. "
                "Transits are potentials that you can witness in others and the world around you, "
                "and, if correct for you, as you follow your individual Strategy and Authority, "
                "may become a part of your experience as well."
            )
        
        return content
    
    def translate_to_chinese(self, text: str) -> str:
        """ä½¿ç”¨ DeepSeek API å°†æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡"""
        if not text:
            return ""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ Human Designï¼ˆäººé¡åœ–ï¼‰ç¿»è­¯å°ˆå®¶ã€‚"
                        "è«‹å°‡ä»¥ä¸‹è‹±æ–‡å…§å®¹ç¿»è­¯æˆæµæš¢ã€æº–ç¢ºçš„ç¹é«”ä¸­æ–‡ã€‚"
                        "ä¿ç•™å°ˆæœ‰åè©å¦‚ Gateã€Channelã€Center ç­‰çš„è‹±æ–‡åŸæ–‡ï¼Œå¯ä»¥åœ¨æ‹¬è™Ÿä¸­åŠ ä¸­æ–‡èªªæ˜ã€‚"
                        "æ³¨æ„ä¿æŒåŸæ–‡çš„å°ˆæ¥­æ€§å’Œæ·±åº¦ã€‚å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
                    )
                },
                {
                    "role": "user",
                    "content": f"è«‹å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ï¼š\n\n{text}"
                }
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }
        
        try:
            response = requests.post(
                self.DEEPSEEK_API_URL,
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥: {e}")
            return f"[ç¿»è¯‘å¤±è´¥] {text}"
    
    def translate_content(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """ç¿»è¯‘æ‰€æœ‰å†…å®¹åˆ°ä¸­æ–‡"""
        chinese_content = {}
        
        # éœ€è¦ç¿»è¯‘çš„å­—æ®µ
        fields_to_translate = [
            'gate_title', 'gate_subtitle', 'lead_description',
            'cross_info', 'quarter_theme', 'main_description',
            'line_title', 'exaltation', 'detriment', 'footer_note'
        ]
        
        print("æ­£åœ¨ç¿»è­¯å…§å®¹ç‚ºç¹é«”ä¸­æ–‡...")
        for field in fields_to_translate:
            if field in content and content[field]:
                print(f"  ç¿»è­¯ {field}...")
                chinese_content[field] = self.translate_to_chinese(content[field])
        
        # å¤åˆ¶ä¸éœ€è¦ç¿»è¯‘çš„å­—æ®µ
        for key in content:
            if key not in chinese_content:
                chinese_content[key] = content[key]
        
        return chinese_content
    
    def generate_markdown_en(self, content: Dict[str, Any]) -> str:
        """ç”Ÿæˆè‹±æ–‡ Markdown æ–‡ä»¶"""
        date_display = datetime.now().strftime("%B %d, %Y")
        
        gate_image = content.get('gate_image_local', content.get('gate_image_url', ''))
        rave_mandala = content.get('rave_mandala_local', '')
        gate_title = content.get('gate_title', '')
        gate_subtitle = content.get('gate_subtitle', '')
        lead = content.get('lead_description', '')
        cross = content.get('cross_info', '')
        quarter = content.get('quarter_theme', '')
        main_desc = content.get('main_description', '')
        line_title = content.get('line_title', '')
        exaltation = content.get('exaltation', '')
        detriment = content.get('detriment', '')
        
        md = f"""# {gate_title}

**{date_display}**

"""
        
        # Gate å›¾ç‰‡
        if gate_image:
            md += f"""![Gate]({gate_image})

"""
        
        md += f"""## *{gate_subtitle}*

> {lead}

"""
        
        if cross:
            md += f"""### {cross}

"""
        
        if quarter:
            md += f"""*{quarter}*

"""
        
        md += """---

"""
        
        if main_desc:
            md += f"""{main_desc}

"""
        
        # Rave Mandala å¤§å›¾
        if rave_mandala:
            md += f"""![Rave Mandala]({rave_mandala})

"""
        
        md += """---

"""
        
        if line_title:
            md += f"""### {line_title}

"""
        
        if exaltation:
            md += f"""**â˜€ï¸ Exaltation:** {exaltation}

"""
        
        if detriment:
            md += f"""**ğŸŒ‘ Detriment:** {detriment}
"""
        
        return md
    
    def generate_markdown_zh(self, content: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¹é«”ä¸­æ–‡ Markdown æ–‡ä»¶"""
        date_display = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        gate_image = content.get('gate_image_local', content.get('gate_image_url', ''))
        rave_mandala = content.get('rave_mandala_local', '')
        gate_title = content.get('gate_title', '')
        gate_subtitle = content.get('gate_subtitle', '')
        lead = content.get('lead_description', '')
        cross = content.get('cross_info', '')
        quarter = content.get('quarter_theme', '')
        main_desc = content.get('main_description', '')
        line_title = content.get('line_title', '')
        exaltation = content.get('exaltation', '')
        detriment = content.get('detriment', '')
        
        md = f"""# {gate_title}

**{date_display}**

"""
        
        # Gate å›¾ç‰‡
        if gate_image:
            md += f"""![é–˜é–€]({gate_image})

"""
        
        md += f"""## *{gate_subtitle}*

> {lead}

"""
        
        if cross:
            md += f"""### {cross}

"""
        
        if quarter:
            md += f"""*{quarter}*

"""
        
        md += """---

"""
        
        if main_desc:
            md += f"""{main_desc}

"""
        
        # Rave Mandala å¤§å›¾
        if rave_mandala:
            md += f"""![äººé¡åœ–æ›¼é™€ç¾…]({rave_mandala})

"""
        
        md += """---

"""
        
        if line_title:
            md += f"""### {line_title}

"""
        
        if exaltation:
            md += f"""**â˜€ï¸ é«˜éšè¡¨é”:** {exaltation}

"""
        
        if detriment:
            md += f"""**ğŸŒ‘ ä½éšè¡¨é”:** {detriment}
"""
        
        return md
    
    def run(self) -> str:
        """æ‰§è¡Œå®Œæ•´çš„æŠ“å–ã€ç¿»è¯‘å’Œç”Ÿæˆæµç¨‹"""
        print("=" * 60)
        print("IHDS Daily View Fetcher")
        print("=" * 60)
        
        # 1. è·å–ç½‘é¡µå†…å®¹
        print("\nğŸ“¥ æ­£åœ¨ç²å–ç¶²é å…§å®¹...")
        html = self.fetch_page()
        print("   âœ… ç¶²é ç²å–æˆåŠŸ")
        
        # 2. è§£æå†…å®¹ï¼ˆä¸ä¸‹è½½å›¾ç‰‡ï¼‰
        print("\nğŸ” æ­£åœ¨è§£æå…§å®¹...")
        en_content = self.parse_content(html)
        print(f"   âœ… è§£ææˆåŠŸï¼ŒGate: {en_content.get('gate_title', 'Unknown')}")
        
        # 3. æ ¹æ®å†…å®¹åˆ›å»ºç›®å½•ï¼ˆæ ¼å¼: 2026-01-06-54.1ï¼‰
        dir_name = self._setup_daily_directory(en_content)
        print(f"   ğŸ“ ç›®éŒ„: {dir_name}")
        
        # 4. ä¸‹è½½å›¾ç‰‡
        print("\nğŸ“· æ­£åœ¨ä¸‹è¼‰åœ–ç‰‡...")
        en_content = self.download_images(en_content)
        
        # 5. ç¿»è¯‘å†…å®¹
        print("\nğŸŒ æ­£åœ¨ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡...")
        zh_content = self.translate_content(en_content)
        print("   âœ… ç¿»è­¯å®Œæˆ")
        
        # 6. ç”Ÿæˆ Markdown æ–‡ä»¶
        print("\nğŸ“ æ­£åœ¨ç”Ÿæˆ Markdown æ–‡ä»¶...")
        print(f"   ğŸ“ ä¿å­˜ç›®éŒ„: {self.output_dir}")
        
        # ç”Ÿæˆè‹±æ–‡ç‰ˆ (ä¿å­˜åˆ°æ—¥æœŸç›®å½•ï¼Œæ–‡ä»¶ååŒ…å«æ—¥æœŸ)
        markdown_en = self.generate_markdown_en(en_content)
        filename_en = f"daily_view_{self.date_str}_en.md"
        filepath_en = self.output_dir / filename_en
        with open(filepath_en, 'w', encoding='utf-8') as f:
            f.write(markdown_en)
        print(f"   âœ… è‹±æ–‡ç‰ˆ: {filepath_en}")
        
        # ç”Ÿæˆç¹é«”ä¸­æ–‡ç‰ˆ
        markdown_zh = self.generate_markdown_zh(zh_content)
        filename_zh = f"daily_view_{self.date_str}_zh.md"
        filepath_zh = self.output_dir / filename_zh
        with open(filepath_zh, 'w', encoding='utf-8') as f:
            f.write(markdown_zh)
        print(f"   âœ… ç¹é«”ä¸­æ–‡ç‰ˆ: {filepath_zh}")
        
        # åŒæ—¶ä¿å­˜ latest ç‰ˆæœ¬åˆ°æ ¹ç›®å½•ï¼ˆå›¾ç‰‡è·¯å¾„æŒ‡å‘å½“å‰æ—¥æœŸç›®å½•ï¼‰
        dir_name = self.output_dir.name  # ä¾‹å¦‚: 2026-01-06-54.1
        latest_markdown_en = markdown_en.replace('images/', f'{dir_name}/images/')
        latest_markdown_zh = markdown_zh.replace('images/', f'{dir_name}/images/')
        
        latest_en_path = self.base_output_dir / "latest_en.md"
        with open(latest_en_path, 'w', encoding='utf-8') as f:
            f.write(latest_markdown_en)
        
        latest_zh_path = self.base_output_dir / "latest_zh.md"
        with open(latest_zh_path, 'w', encoding='utf-8') as f:
            f.write(latest_markdown_zh)
        print(f"   âœ… æœ€æ–°è‹±æ–‡ç‰ˆ: {latest_en_path}")
        print(f"   âœ… æœ€æ–°ä¸­æ–‡ç‰ˆ: {latest_zh_path}")
        
        print("\n" + "=" * 60)
        print("âœ¨ å®Œæˆ!")
        print("=" * 60)
        
        return str(filepath_en)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='IHDS Daily View Fetcher')
    parser.add_argument(
        '--api-key',
        type=str,
        default=os.environ.get('DEEPSEEK_API_KEY', 'sk-b006820f1cfd4c54ae530ccc0ed6dd5a'),
        help='DeepSeek API Key'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='Output directory for generated files'
    )
    
    args = parser.parse_args()
    
    fetcher = IHDSDailyViewFetcher(
        deepseek_api_key=args.api_key,
        output_dir=args.output_dir
    )
    
    fetcher.run()


if __name__ == "__main__":
    main()

